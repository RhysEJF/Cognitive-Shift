---
title: 'Why AI "taking our jobs" is the best thing that could happen to us'
excerpt: "The execution bottleneck that has kept great ideas trapped in busywork is dissolving and what's left is pure creative potential."
authors: ["rhys-fisher"]
publication: "let-them-run"
publishedAt: 2026-02-18
tags: []
---

Have you ever been surfing and felt the wave pick you up? There's this moment, right before you know whether you're going to ride it or eat it, where the ocean decides for you. You're either paddling hard enough or you're not. There's no negotiating with it.

That's where we are with AI right now. Everyone can feel the wave. The difference is that most people are standing on the beach yelling about how dangerous the water is, while a small group of people are already up and riding.

I get the fear. I really do. Smart people I respect are saying that white-collar work gets decimated within five years. They might be right about the disruption. But they're dead wrong about what comes after.

## Your best thinking is buried in busy work

Here's what nobody talks about. Most knowledge workers spend most of their time on tasks that don't require their best thinking. Formatting slides. Writing status updates. Synthesising data into reports that nobody reads. Doing research that an AI can now do in thirty seconds.

We've spent decades trapping human potential in the weeds. The brilliant strategist who spends her afternoons in spreadsheets. The founder with a world-changing idea who's drowning in admin. The engineer who could be architecting something beautiful but is stuck debugging a CSS issue that an AI already knows how to fix.

AI doesn't replace the human. It replaces the weeds. And what's left, once you strip away all the execution grunt work, is the thing that actually matters. Vision, taste, judgement, and the ability to think about problems nobody has thought about before.

I believe this will spark an ideas renaissance.

For the first time in history, having a great idea AND the ability to execute on it is accessible to almost anyone. You don't need a team of fifty. You don't need venture funding to hire engineers. You need a clear vision and the ability to direct AI to build it. The barrier between idea and reality just collapsed.

## The economics actually back this up

I know *"it'll be fine"* isn't a satisfying argument. So let me give you four economic concepts that explain why the humans-become-useless narrative falls apart under scrutiny.

**When intelligence gets cheaper, we don't use less of it, we use more**: Jevons Paradox. When coal got cheaper in the 1800s, we didn't use less coal, we used astronomically more. Same thing is happening with intelligence. As AI makes cognitive work cheaper, we'll demand a hundred times more of it. And the human who's directing that intelligence? They become the bottleneck. Bottlenecks don't get cheaper. They get very, very well paid.

**Everything AI can't improve becomes more expensive:** A hairdresser today earns dramatically more than a hairdresser a hundred years ago. Not because they cut hair any better, that hasn't changed. It's because the people buying haircuts have more money, and the human experience of the service is the value. Baumol's Cost Disease means that when productivity rises everywhere else, the things that stay human become premium. Trust, curation, community, human presence, these appreciate as AI commoditises everything cognitive.

**Even if AI is better than you at everything, you still have a role**: trade happens based on opportunity cost, not absolute ability. Roger Federer might genuinely be a better driver than his chauffeur. But he should be playing tennis, because that's where his time is most valuable. Same with AI, even when it's superhuman at a task, if it's more superhuman at other tasks, the lower-value work defaults back to humans. There's always something for us to do, and it pays better than you'd think.

**AI can't handle what it hasn't seen before:** Everything AI is good at comes from its training data. The entire internet, essentially. But anything novel, any new situation, any out-of-distribution problem, any task where there are only five examples in existence, and it falls apart. Humans are built for low-information environments. We extrapolate from a single data point. We generate the first examples of the new thing. We're the scouts, creating the future training sets that AI will eventually learn from. That's not going away.

## So what does this mean for you?

It means the value is shifting. Fast. It's no longer about doing the work, it's about having a say on what work to do. The person who can see clearly, think originally, and direct an AI workforce to execute on that vision is going to be absurdly valuable. The person who's still competing with AI on execution speed is going to have a bad time.

I used to fly paragliders. In that world, you learn very quickly that an honest assessment of conditions is the only thing keeping you alive. You can't bullshit the wind. The same applies here. You can either see what's actually happening with AI and position yourself for what comes next, or you can stand on the beach telling everyone the wave is too dangerous.

The wave doesn't care what you think about it. It's coming regardless.

The people who understand this, who are already building with AI, experimenting with AI workforces, learning to direct rather than execute, they're not worried about their jobs. They're too busy building things that weren't possible this time last year.

The execution bottlenecks are dissolving. What's left is pure creative potential. The question isn't whether AI takes your job. The question is, when it handles the execution, what will you build?

So define the vision and **let them run**...
